


## 1   产品大方向：让决策可学习

我们的核心命题是：
在产品与工程协作中，  **关键决策是否能被后续的协作者或 AI 学会、复用、验证**，而不是只被执行一次。

我们的产品大方向不是效率，而是**学习能力**。
## 2   什么叫「让决策可学习」

在产品逻辑上可拆解为两个递进的方向：

1. **把决策记录下来**：
	1. 系统是否真的“记住了我们做过什么决定、否定过什么可能性”。
	2. 这一步我们要解决“发生了什么”和“为什么这么做”的数据捕获问题。这是基础，对抗的是“决策失忆” 。
    
2. **让记录的内容可学习**：
	1. 即使记录下来了，它是否能被**下一个人 / AI**真正理解、复用？
	2. 这一步我们要解决“记录下来的数据如何被复用、被计算、被进化”的问题。

## 3   What's the status quo

### 3.1   “把决策记录下来”的现状

目前行业内缺乏能同时承载意图（Why）和实现（What）的统一媒介 。

- **大厂工作流**
    
    - **现状：** 信息被割裂在不同工具中——需求在飞书/文档，任务在 Jira，代码在 GitHub 。
        
    - **问题：** 
	    - 决策被拆散在多个系统中。
	    - 多数“为什么这样决定”只存在于会议当下。
	    - 个人判断无法沉淀为组织资产

        
- **Google 工作流**
    
    - **现状：** 依赖 Google Docs、Meet 和 Email 。
        
    - **问题：** 语料很多，但类型不区分，无法回答：
		- 这是建议还是结论？
		- 是否被采纳？
		- 是否成功？
        
- **Vibe Coding 工作流**
    
    - **现状：** 使用 Cursor/Lovable 等 AI 工具快速生成代码 。
        
    - **问题：**
	    - 只记录“做了什么”，不记录“为什么这样做”
		- 被否定的方案、改稿过程大量流失
		- AI 无法从历史中校准行为
### 3.2   “让记录的内容可学习”的现状

大多数工具只做到了“存储”，没做到“知识资产化” 。

1. **大厂工作流:**
    
    - **现状：**
		- 决策多为**文本叙述**
		    
		- 缺少结构化、可验证表达
		    
		- 后续只能“读”，无法“用”
        
    - **问题：** 学习周期极长（慢循环），且难以被机器读取或自动化执行。
        
2. **Google 工作流:**
    
    - **现状：** 靠“关键词搜索”。
        
    - **问题：** 只能检索到“文本”，无法检索到“因果逻辑”。你可以搜到一份文档，但搜不到“为什么上次A方案失败了”。
        
3. **Vibe Coding 工作流:**
    
    - **现状：** 
	    - 有三种常见尝试：
				
			1. **长期规则类**（cursor rules / claude skills）  
			    → 执行快，但缺乏校准反馈
			    
			2. **意图-执行连接类**（Linear / CodeStream）  
			    → 只记录“做 / 不做”，丢失 reasoning
			    
			3. **结果打分类**（LangSmith / Evals）  
			    → 对工程师友好，对 PM 极不友好
        
    - **问题：** 这是静态的规则（Rule-based）。它们缺乏反馈机制，假定用户写下的规则永远是对的，无法根据实际运行结果自动进化 。
		
7. **飞书 (Lark) / RAG Bots:**
    
    - **现状：** 在聊天中自动插入基于文档库的 AI 回复。
        
    - **问题：** 
	    - 无法追溯、校验、复用。它能回答“文档里有什么”，但无法判断“基于历史教训，我现在该做什么决策”。
	        
	    - 本质仍是“更聪明的摘要”，是信息检索，而非决策辅助。

## 4   What we did

### 4.1   关于“把决策记录下来”

- **实验设计：** 测试用户对于“打断工作流程来记录决策”的接受度（Effort vs Benefit）。

	- 设计多个真实决策场景（规则、结构、流程）
	    
	- 控制记录时机（Before / After）
	    
	- 测试用户对“记录行为”的接受度
			
		- 主观体验（打断感 / 有用性）
		
		- 

- **结论**

	- 用户**并不反感被打断**
	    
	- 前提是他们理解这是为了**未来的自己或队友省力**
	    
	- 多数用户更偏好 **Before（事前）明确规则**  
	    → 原因是他们希望Jason接手工作之前就获得更完整的信息
### 4.2   关于“让记录的内容可学习”

- **实验设计：** 这种记录应该长什么样？我们对比了 4 种记录形式，测试其对后续决策准确率的影响 。
	- 记录形式
    
	    - F1: 原始聊天记录（对照组）
	        
	    - F2: 纯 Event Log（流水账）
	        
	    - F3: Event Log + 依据（Tag）
	        
	    - F4: Event Log + 总结性结论 (Summary)
		
	- 衡量：

		- **Coverage**（关键信息是否被覆盖）
		    
		- **Accuracy**（是否写对）
		    
	    - 难度 / 信心 / 帮助感 
		    
- **结论：**
    
    - **单纯的 Log 是无效的：** F2（纯 Log）导致决策准确率下降，甚至不如直接看聊天记录。因为信息密度太低，增加了阅读负担 。
        
    - **结构化 Tag 并不够：** F3（加 Tag）虽然提供了结构，但用户需要脑补 Tag 的含义，信心度反而最低 。
        
    - **总结才是关键：** F4（总结性结论）的主观体验最好。用户既觉得容易理解，又觉得最有帮助。**但在复杂决策（S3 / S4）中：**
    
	    - 主观信心 ≠ 客观正确
	        
	    - 用户产生严重“理解幻觉”
        
    - **核心洞察：** 
	    - 产品不能做成一个“更细致的 Log 系统”。不要把 Consensus History 做成 Transcript Archive。**要“压缩 + 收敛”**，提供经过提炼的结论 。
	    - 对复杂决策，仅优化“附件形态”是治标不治本，必须优化“决策表达层”。

## 5   What we will do and how we will do it 

基于上述结论，我们将构建一个由 Agent 驱动的闭环系统，而非简单的编辑器。
### 5.1   我们不会做什么

- ❌ 更细的 Log 系统
    
- ❌ Transcript Archive
    
- ❌ 让用户持续“解释过程”

### 5.2   我们要做什么（核心方向）

- 关于 **把决策记录下来**：
		
	- 行为记录的压缩 + 决策记录的收敛

		- AI 生成**总结性决策草稿**
		    
		- 用户只做 Review / 选择
		    
		- 默认输出 **Cleaned & Structured** 的指令
		
	- 针对不同决策复杂度，提供不同表达能力
		
		- 简单约束 → 自动抽取 / 高亮
		    
		- 结构决策 → 模板 + 校验
		    
		- 复杂逻辑 →
		    
		    - 分段函数
		        
		    - 例外集
		        
		    - 状态机 / 流程表达

- 关于 **让记录的内容可学习**：

	- 针对人的学习，在 F4 （log+summary）的基础上，继续寻找更优的记录形式
	
		- 
    
	- 用可追溯性（Traceability）解决幻觉
	
		- Summary ≠ 黑盒
		    
		- 必须能回溯证据链
		    
		- 避免理解幻觉
	    
### 5.3   产品架构图

#### Layer A 用户感知层（UI/入口）

- Dashboard
    
- Editor
    
- Trace / Explore View

#### Layer B 功能模块层

- Intent 
	
- Decision 
	
- Execution 
	
- Verification 
	
- Learnability 

#### Layer C 数据与对象层

- Intent Block
    
- Decision Artifact（Summary / Rule / Flow）
    
- Event
    
- Evidence（引用/证据片段）
    
- Result Metric

#### Layer D 外部

- Git / repo
    
- Docs/IM（飞书/Google）
    
- Issue tracker（Jira/Linear）
    
- AI 工具（Cursor/Lovable…）