# Elfiee 项目目标与里程碑

**时间单位**：
- 大周期：2个月（8周）
- 小周期：2周（Sprint）

---

## 目标设计原则

基于 Elfiee 的五个核心设计需求，采用**递进式验证**策略：

```
需求1: 统一工作面 ──┐
需求2: Event记录/分类/回放   ──┤→ 阶段1: 人类协作基础（MVP）
                     │
                    ─→ 阶段2: 人与AI单轮协作
                     │
需求3: DAG关系链条  ──→ 阶段3: 逻辑链条推理
                     │
                    ─→ 阶段4: 人与AI多轮协作 ─→阶段7：外部验证和推广
                     │
需求4: CBAC权限    ──→ 阶段5: 可复用模板 
                     │
需求5: 分布式冲突  ──→ 阶段6: 离线协作能力
```

---

## 阶段1：MVP - 人类协作基础（Week 1-2，Demo Day）

### 目标
**在不使用AI的前提下**，验证 Elfiee 作为多角色协作平台的基础能力。

### 核心需求
- ✅ 需求1：统一工作面（Literature Programming）
- ✅ 需求2：Event记录/分类/回放（Event Sourcing基础）

### 功能范围

#### 1.1 统一工作面（需求1）
- [ ] Block编辑器：支持Markdown
- [ ] 单机协作：单人单机多角色编辑同一份文档
- [ ] 文档结构：文档AST分块，高亮显示，可引用其他文档，支持点击跳转
- [ ] 代码运行（option）：可调用本地python/其他解释器

#### 1.2 Event记录/分类/回放（需求2）
- [ ] 记录所有修改事件：时间戳、角色、修改内容
- [ ] Timeline可视化：（向量）时间轴展示所有事件
- [ ] 基础回放：点击Timeline节点，文档回退到该时刻
- [ ] 对比视图：显示修改前后的差异
- [ ] Event分类：按用户、分类筛选Event
- [ ] Event搜索：根据关键词搜索历史事件 

### 验证场景
**内部场景**：团队完成"Elfiee Editor页面terminal功能"的开发

### 量化指标

| 指标类型 | 具体指标 | 目标值 | 验证方式 |
|---------|---------|--------|---------|
| **功能完整性** | 核心功能实现率 | 100% | 功能清单checklist |
| **Event记录** | Event记录完整性 | 30 | 每次操作都有对应Event，至少记录30条event |
| **协作效率** | 需求澄清次数 | <10次 | 统计提问"为什么这么做"并进行修改的次数 |
| **决策可追溯** | 关键决策记录率 | 100% | 至少3个关键决策有理由记录 |
| **Timeline回放** | 回放准确率 | 100% | 回退到任意时刻，文档状态正确 |
| **完成开发任务** | terminal 功能实现 | terminal可以运行导入项目中的测试代码 | PR/评审通过率 |

### 交付物
- [ ] 可运行的Elfiee原型（Dashboard页面开发的完整记录）
- [ ] 至少30条Event记录（覆盖需求讨论、设计、编码、Review）
- [ ] Demo Day演示PPT
- [ ] 内部复盘文档（记录遇到的问题和改进方向）

### 成功标准
- ✅ 团队成员都能独立使用Elfiee进行协作
- ✅ Timeline能清晰展示"需求如何从模糊到清晰"的过程
- ✅ 任何新成员加入，能通过Timeline快速了解项目背景

---

## 阶段2：人与AI单轮协作（Week 3-4）

### 目标
在已有的Event记录基础上，**引入AI能力**，验证使用Elfiee进行AI协作的可行性。

### 核心需求
- ✅ 需求1、2扩展：AI功能

### 功能范围

#### 2.1 AI能力集成
- [ ] 配置AI
- [ ] 对话：任意位置根据上文开启对话
- [ ] 补充：任意位置根据上文补充内容
- [ ] 结构化：任意位置根据上文梳理需求，生成验证标准和测试
- [ ] 文件修改：任意位置根据上文进行导入文件的修改，并添加引用
- [ ] Event分类：自动识别事件类型（需求变更/技术决策/Bug修复）（Opition）
- [ ] 智能摘要：AI总结某个时间段的关键事件 （Option）

### 验证场景
**内部场景**：使用Elfiee完成"Editor页面留言功能（新extension）"的开发

**AI参与方式**：
- AI协助产品：根据用户故事生成结构化需求和测试用例
- AI协助开发：根据测试用例生成初版代码
- AI协助Review：分析当前实现和Event历史，指出潜在问题

### 量化指标

| 指标类型 | 具体指标 | 目标值 | 对比基准（阶段1） |
|---------|---------|--------|------------------|
| **AI生成质量** | 代码首次通过率 | >60% | N/A（新能力） |
| **协作效率** | 需求澄清次数 | <5次 | 阶段1: <10次 |
| **开发效率** | 功能完成时间 | <3天 | 预估纯人工需15天 |
| **理由完整性** | 关键决策有AI生成理由 | N/A | 阶段1: 100%人工 |

### 交付物
- [ ] AI集成的Elfiee版本
- [ ] 留言功能开发的完整记录（包含AI参与的Event）
- [ ] AI效果评估报告（对比阶段1的纯人工协作）

### 成功标准
- ✅ 最终版本AI生成的需求、测试用例，至少80%可直接使用
- ✅ AI能准确引用历史Event，减少重复讨论
- ✅ 团队可每日进行两轮以上的修改，并提交不少于一次的PR

---

## 阶段3：逻辑链条可视化（Week 5-6）

### 目标
实现**非线性知识关系**的可视化，让团队能看到决策之间的因果关系。

### 核心需求
- ✅ 需求3：DAG关系链条（因果推断、聚类、搜索）

### 功能范围

#### 3.1 DAG关系建模和数据结构调整
- [ ] 添加和验证必要的数据结构
- [ ] 引用关系追踪：Block A引用Block B，自动建立链接
- [ ] Event因果关系推断：parse event db，自动识别"Event A导致Event B"
- [ ] 决策依赖图：可视化"这个决策依赖哪些前提，造成哪些影响"，形成nx风格DAG图。
- [ ] DAG环检测：添加引用时，检测环并阻止操作。


#### 3.2 DAG分析（option）
- [ ] 交互式探索：点击节点，展示相关联的Event
- [ ] 路径高亮：追溯"从需求到实现"的完整路径
- [ ] 聚类视图：将相关Event聚类显示（如"支付功能"相关的所有讨论）

### 验证场景
**内部场景**：回顾阶段1和阶段2的项目，挂载DAG结构，可视化逻辑链条

**验证内容**：
- 追溯"comment为什么这样设计"的完整决策链
- 分析"Editor页面terminal"的技术选型依据
- 识别"哪些需求变更导致了架构调整"

### 量化指标

| 指标类型 | 具体指标 | 目标值 | 验证方式 |
|---------|---------|--------|---------|
| **因果推断准确率** | 自动识别的因果关系正确率 | >70% | 人工验证10条关系 |
| **知识复用** | 新成员理解项目时间 | <1小时 | 新成员通过DAG图快速理解 |
| **决策追溯** | 关键决策溯源完整性 | 100% | 至少5个决策能追溯到根源 |

### 交付物
- [ ] DAG关系引擎（后端算法）
- [ ] DAG可视化组件（前端）
- [ ] 阶段1+2项目的完整逻辑链条

### 成功标准
- ✅ 任意一个决策，都能通过DAG图追溯到根源
- ✅ 新成员通过知识图谱，1小时内理解项目80%的背景
- ✅ 团队认为知识图谱"确实有用"（满意度>8/10）
- ✅ 发现1个"被遗忘的依赖"或“过度的修改”（通过影响分析发现）
---


## 阶段4：基于elfiee的AI多轮协作（Week 6-9）

### 目标
实现基于**非线性知识关系**的AI多轮协作，跑benchmark。

### 核心需求
- ✅ 需求3：DAG关系链条

### 功能范围

#### 4.1 基于event的多轮协作算法和benchmark
- [ ] 算法开发：规范AI prompt范式
- [ ] 算法开发：自动生成event+逻辑链+需求的prompt
- [ ] 实验设计：基于SWE-BENCH的开发任务实验以及消融实验

#### 4.2 实际应用验证
- [ ] 实际开发任务验证设计
- [ ] 实际开发任务执行

### 验证场景
**内部场景**：在elfiee开发任务以外的任务中，实现半自动/全自动的需求/测试/实现/验证的流程。

**验证内容**：
- 能否配置不同agent，独立完整全链条开发
- 能否将任务快速迁移至不同agent
- 多阶段agent的prompt记录
- 多阶段agent的修改轮次

### 量化指标

| 指标类型 | 具体指标 | 目标值 | 验证方式 |
|---------|---------|--------|---------|
| **SWEbench打分** | SWEbench任务完成打分 | 搭配轻量化模型，达到SOTA或近似SOTA水平 | SOTA 打分 |
| **使用效率** | 执行elfiee以外开发任务效率 | 需要三人以上配合的任务中，开发周期缩短30% | 实际开发体验，用户调查 |

### 交付物
- [ ] SWEbench打分
- [ ] 用户调查报告。A/B test

### 成功标准
- ✅ SWE bench达到轻量化模型（<30B）的SOTA
- ✅ 通过A/B test，实际开发提效。
---


## 阶段5：可复用模板（Week 10-12）

### 目标
实现**CBAC权限模型**，将协作过程沉淀为可复用的.elf模板。

### 核心需求
- ✅ 需求5：CBAC动态权限（可执行的协作规则）

### 功能范围

#### 5.1 CBAC权限系统（需求4）
- [ ] 角色权限定义：PM/前端/后端/测试的权限范围
- [ ] 动态权限调整：根据业务逻辑调整权限
- [ ] 权限验证：修改时自动检查权限
- [ ] 审批流程：超出权限的修改需要审批（option）

#### 5.2 模板系统
- [ ] 保存为模板：将整个协作过程保存为.elf模板文件
- [ ] 模板包含：角色/agent定义、权限配置、任务文件模板
- [ ] 模板实例化：新项目套用模板，自动创建任务文件模板和协作流程
- [ ] 模板市场（内部）：团队内共享模板


### 验证场景
**内部场景1**：提取"功能开发"通用模板

**模板内容**：
- 角色：PM、前端、后端、测试、Owner
- 权限：PM定义需求，开发实现，测试验证，Owner Review的流程
- 验收标准：功能完整、测试通过、代码Review通过

**内部场景2**：使用模板讨论"运营方案"

### 量化指标

| 指标类型 | 具体指标 | 目标值 | 对比基准 |
|---------|---------|--------|---------|
| **权限准确性** | 越权操作拦截率 | 100% | 模拟10次越权操作 |
| **模板可用性** | 模板实例化成功率 | 100% | 至少3个新项目 |
| **启动效率** | 使用模板的项目启动时间 | <30分钟 | 不用模板需2小时 |

### 交付物
- [ ] CBAC权限规则引擎
- [ ] 至少2个通用模板（功能开发、文档讨论）
- [ ] 模板使用指南

### 成功标准
- ✅ 团队成员能独立创建和使用模板
- ✅ 新项目使用模板后，启动时间缩短75%以上
- ✅ 权限系统没有造成"过度约束"（团队满意度>7/10）

---

## 阶段6：离线协作能力（Week 12-15）

### 目标
实现**分布式冲突检测**，支持多人离线协作后的精准合并。

### 核心需求
- ✅ 需求6：Event-based Vector Clock（离线协作）

### 功能范围

#### 6.1 Vector Clock系统（需求5）
- [ ] Event时间戳：每个Event带Vector Clock
- [ ] 因果序推断：判断Event A是否发生在Event B之前
- [ ] 并发检测：识别两个Event是否并发（可能冲突）
- [ ] 冲突类型识别：修改冲突、逻辑冲突、依赖冲突

#### 6.2 离线协作支持
- [ ] 离线编辑：本地修改，不需要联网
- [ ] 离线同步：联网后自动同步Event
- [ ] 冲突标记：自动标记冲突的Block
- [ ] 冲突解决界面：展示冲突详情，辅助人工解决


### 验证场景 （待定）
**内部场景**：模拟"前端和后端同时离线工作"

**场景设置**：
- 前端离线修改：UI组件升级
- 后端离线修改：API接口调整
- 两者都修改了"数据格式定义"Block → 冲突

**验证内容**：
- 系统能否准确检测冲突
- 冲突解决界面是否清晰
- 解决冲突后，Event历史是否完整

### 量化指标

| 指标类型 | 具体指标 | 目标值 | 验证方式 |
|---------|---------|--------|---------|
| **冲突检测准确率** | 真实冲突识别率 | >90% | 模拟20次并发修改 |
| **冲突检测准确率** | 误报率 | <10% | 统计错误标记的冲突 |
| **因果序准确率** | Event顺序推断正确率 | >95% | 验证100对Event关系 |
| **同步效率** | 离线Event同步时间 | <10秒 | 同步100条Event |
| **冲突解决** | 人工解决冲突平均时间 | <5分钟/次 | 统计10次冲突解决 |

### 交付物
- [ ] Vector Clock算法实现
- [ ] 离线协作Demo
- [ ] 冲突解决界面
- [ ] 分布式协作技术文档

### 成功标准
- ✅ 模拟的20次并发修改，冲突检测无遗漏
- ✅ 团队成员理解Vector Clock的基本原理
- ✅ 离线协作不会"丢失"任何Event
- ✅ 冲突解决界面让团队满意（>7/10）

---

## 7：外部验证与推广（Week 6-15，开源和商业计划）

### 目标
将Elfiee推向外部用户，进行真实场景验证，收集反馈并迭代。

### 验证策略

#### 7.1 开源计划
**场景**：当Elfiee初步具备多轮多AI协作的能力时，进行开源，并公布benchmark结果和使用报告

#### 7.2 外部测试（Week 16-17）
**目标用户**：5-10个外部用户（朋友、合作伙伴）

**测试场景**：
- 创业团队（2-3人）的内部项目
- B2C协作（需求+实现，瞄准需求不明确或者可能频繁变化的多方项目）


### 量化指标

| 指标类型 | 具体指标 | 目标值 | 验证方式 |
|---------|---------|--------|---------|
| **开源计划** | stars | >300 | github star |
| **开源计划** | 转发/报道 | >5 | 科技媒体 |
| **外部测试** | NPS（净推荐值） | >8/10 | 外部用户问卷 |
| **外部测试** | 留存率（7天） | >60% | 统计回访用户 |
| **外部测试** | 用户反馈搜集 | >50个 | 收集反馈 |

### 交付物
- [ ] 开源仓库
- [ ] 外部用户反馈汇总
- [ ] 产品路线图

### 成功标准
- ✅ 内部团队日常开发使用Elfiee（替代Notion+飞书）
- ✅ 外部用户NPS>8，至少5个用户愿意持续使用
- ✅ 发现并整理至少10个核心改进方向

---

## 里程碑总结

| 阶段 | 时间 | 核心需求 | 关键验证 | 量化目标 |
|------|------|---------|---------|---------|
| **阶段1: MVP** | Week 1-2 | 需求1+2基础 | 内部协作 | 功能完整性，完成任务数 |
| **阶段2: 人与AI单轮协作** | Week 3-4 | 需求1+2完整 | AI效果 | 协作效率，开发效率 |
| **阶段3: 逻辑链条可视化** | Week 5-6 | 需求3 | 知识图谱 | 推断准确率，新用户理解效率 |
| **阶段4: AI多轮协作** | Week 6-9 | 需求1+2+3完整 | 模板使用 | benchmark打分，协作效率 |
| **阶段5: 可复用模板** | Week 10-12 | 需求4 | 冲突检测 | 功能完整性，启动/配置效率 |
| **阶段6: 离线协作能力** | Week 12-15 | 需求5 | 真实场景 | 冲突检测准确率，冲突解决效率 |
| **阶段7: 外部验证** | Week 12-15 | 全部 | 真实场景 | stars, 反馈，用户评价 |

---
